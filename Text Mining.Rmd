```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

This file makes use of data that were adapted from:
https://www.ted.com/talks

#Install and load required packages
```{r}
#install.packages("tm")       
#install.packages("text2vec") 
library(tm)
library(text2vec)
```

## Reading the Transcripts file
```{r}
data <- read.csv(file = 'transcripts.csv', header = F, sep = '|')
doc <- 0
for (i in c(2:100)) {doc[i] <- as.character(data$V1[i])}
doc.list <- as.list(doc[2:100])
N.docs <- length(doc.list)
names(doc.list) <- paste0("Doc", c(1:N.docs))
Query <- as.character(data$V1[1])
```

## Preparing the Corpus
```{r}
my.docs <- VectorSource(c(doc.list, Query))
my.docs$Names <- c(names(doc.list), "Query")
my.corpus <- Corpus(my.docs)
my.corpus
```

## Cleaning and Preprocessing the text (Cleansing Techniques)
```{r}
library(SnowballC)

getTransformations()
my.corpus <- tm_map(my.corpus, removePunctuation)

my.corpus <- tm_map(my.corpus, content_transformer(tolower))
# This technique is necessary so that all the words are in a standard form and not treated differently

my.corpus <- tm_map(my.corpus, removeWords, stopwords("english"))
# Stop words usually appear in high frequencies and carry little meaning. You will likely get better information retrieval when you apply this pre-processing technique.  

my.corpus <- tm_map(my.corpus, stemDocument)
# Stemming converts words close to a standard form. This pre-processing technique trims the suffixes and prefixes of the original words

```

## Creating a uni-gram Term Document Matrix
```{r}
term.doc.matrix <- TermDocumentMatrix(my.corpus)
inspect(term.doc.matrix[1:10,1:10])
```

## Converting the generated TDM into a matrix and displaying the first 6 rows and the dimensions of the matrix
```{r}
term.doc.matrix <- as.matrix(term.doc.matrix)
head(term.doc.matrix)
dim(term.doc.matrix)
```

## Declaring weights (TF-IDF)
```{r}
get.tf.idf.weights <- function(tf.vec) {
  n.docs <- length(tf.vec)
  doc.frequency <- length(tf.vec[tf.vec > 0])
  weights <- rep(0, length(tf.vec))
  relative.frequency <- tf.vec[tf.vec > 0] / sum(tf.vec[tf.vec > 0])
  weights[tf.vec > 0] <-  relative.frequency * log(n.docs/doc.frequency)
  return(weights)
}
```

### Computing Cosine Similarity and Displaying a heatmap
```{r}
tfidf.matrix <- t(apply(term.doc.matrix, 1,
                        FUN = function(row) {get.tf.idf.weights(row)}))

colnames(tfidf.matrix) <- my.docs$Names

head(tfidf.matrix)
dim(tfidf.matrix)

similarity.matrix <- sim2(t(tfidf.matrix), method = 'cosine')
heatmap(similarity.matrix)
```

## Showing the Results
```{r}
sort(similarity.matrix["Query", ], decreasing = TRUE)[1:10]
```

## Creating a bi-gram Term Document Matrix
```{r}
# The bigram can be defined as follows: 
#install.packages('RWeka')
#install.packages('tokenizers')
library(tokenizers)
library(RWeka)

my.corpus2 <- VCorpus(my.docs)
my.corpus2

getTransformations()
my.corpus2 <- tm_map(my.corpus2, removePunctuation)
my.corpus2 <- tm_map(my.corpus2, content_transformer(tolower))
my.corpus2 <- tm_map(my.corpus2,removeWords,stopwords("english"))
my.corpus2 <- tm_map(my.corpus2, stemDocument)


BigramTokenizer <- function(x){ unlist(lapply(ngrams(words(x),2),paste,collapse = " "), use.names = FALSE)}

term.doc.matrix.bigram = TermDocumentMatrix(my.corpus2, control = list(tokenize = BigramTokenizer))
inspect(term.doc.matrix.bigram[1:10,1:10])

term.doc.matrix.bigram <- as.matrix(term.doc.matrix.bigram)
head(term.doc.matrix.bigram)
dim(term.doc.matrix.bigram)

get.tf.idf.weights.bigram <- function(tf.vec) {
  n.docs <- length(tf.vec)
  doc.frequency <- length(tf.vec[tf.vec > 0])
  weights <- rep(0, length(tf.vec))
  relative.frequency <- tf.vec[tf.vec > 0] / sum(tf.vec[tf.vec > 0])
  weights[tf.vec > 0] <-  relative.frequency * log(n.docs/doc.frequency)
  return(weights)
}


tfidf.matrix.bigram <- t(apply(term.doc.matrix.bigram, 1,
                        FUN = function(row) {get.tf.idf.weights.bigram(row)}))

colnames(tfidf.matrix.bigram) <- my.docs$Names

head(tfidf.matrix.bigram)
dim(tfidf.matrix.bigram)

similarity.matrix.bigram <- sim2(t(tfidf.matrix.bigram), method = 'cosine')
heatmap(similarity.matrix.bigram)

sort(similarity.matrix.bigram["Query", ], decreasing=TRUE)[1:10]
```
